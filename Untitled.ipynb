{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71b20dd9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 7500 features, but KNeighborsClassifier is expecting 3750 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m crop_img\u001b[38;5;241m=\u001b[39mframe[y:y\u001b[38;5;241m+\u001b[39mh,x:x\u001b[38;5;241m+\u001b[39mw,:]\n\u001b[0;32m     42\u001b[0m resized_img\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mresize(crop_img,(\u001b[38;5;241m50\u001b[39m,\u001b[38;5;241m50\u001b[39m))\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m output\u001b[38;5;241m=\u001b[39m\u001b[43mknn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresized_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m ts\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     45\u001b[0m date\u001b[38;5;241m=\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mfromtimestamp(ts)\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\face\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:271\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(probabilities, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[1;32m--> 271\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\face\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:826\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    824\u001b[0m         X \u001b[38;5;241m=\u001b[39m _check_precomputed(X)\n\u001b[0;32m    825\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 826\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    828\u001b[0m n_samples_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples_fit_\n\u001b[0;32m    829\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_neighbors \u001b[38;5;241m>\u001b[39m n_samples_fit:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\face\\Lib\\site-packages\\sklearn\\base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\face\\Lib\\site-packages\\sklearn\\base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    446\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 7500 features, but KNeighborsClassifier is expecting 3750 features as input."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os \n",
    "import csv\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from datetime import datetime\n",
    "\n",
    "from win32com.client import Dispatch\n",
    "\n",
    "def speak(str1):\n",
    "    speak=Dispatch((\"SAPI.SpVoice\"))\n",
    "    speak.Speak(str1)\n",
    "\n",
    "\n",
    "video=cv2.VideoCapture(0)\n",
    "\n",
    "facedetect=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "with open('data/names.pkl','rb') as w:\n",
    "    LABELS=pickle.load(w)\n",
    "\n",
    "with open('data/face_data.pkl','rb') as f:\n",
    "    FACES=pickle.load(f)\n",
    "\n",
    "knn=KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(FACES,LABELS)\n",
    "\n",
    "imgbackground=cv2.imread(\"bg.png\")#picture to be inputted\n",
    "\n",
    "COL_NAMES=['NAME','TIME']\n",
    "\n",
    "while True:\n",
    "    ret,frame=video.read()\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    face=facedetect.detectMultiScale(gray,1.3,5)\n",
    "\n",
    "    for (x,y,w,h) in face:\n",
    "        crop_img=frame[y:y+h,x:x+w,:]\n",
    "        resized_img=cv2.resize(crop_img,(50,50)).flatten().reshape(1,-1)\n",
    "        output=knn.predict(resized_img)\n",
    "        ts=time.time()\n",
    "        date=datetime.fromtimestamp(ts).strftime(\"%d-%m-%Y\")\n",
    "        timestamp=datetime.fromtimestamp(ts).strftime(\"%H:%M-%S\")\n",
    "        exist=os.path.isfile(\"attendance/attendance_\"+date+\".csv\")\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255),1)\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(50,50,255),2)\n",
    "        cv2.rectangle(frame,(x,y-40),(x+w,y),(50,50,255),-1)\n",
    "        cv2.putText(frame,(x,y),(x+w,y+h),(50,50,255),1)\n",
    "        attendance=[str(output[0]),str(timestamp)]\n",
    "    imgbackground[162:162+480,55:55+640]=frame\n",
    "\n",
    "    \n",
    "    cv2.imshow(\"frame\",imgbackground)\n",
    "    k=cv2.waitKey(1)\n",
    "    if k==ord('o'):\n",
    "        speak(\"Attendance Taken..\")\n",
    "        time.sleep(5)\n",
    "\n",
    "        if exist:\n",
    "            with open(\"attendance/attendance_\"+date+\".csv\",\"+a\") as csvfile:\n",
    "                writer=csv.writer(csvfile)\n",
    "                writer.writerow(attendance)\n",
    "            csvfile.close()\n",
    "\n",
    "        else:\n",
    "            with open(\"attendance/attendace_\"+date+\".csv\",\"+a\") as csvfile:\n",
    "                writer=csv.writer(csvfile)\n",
    "                writer.writerow(COL_NAMES)\n",
    "                writer.writerow(attendance)\n",
    "            csvfile.close()\n",
    "\n",
    "    if k==ord('q'):\n",
    "        break\n",
    "\n",
    "video.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d5cbb4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 30000 features, but KNeighborsClassifier is expecting 3750 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 47\u001b[0m\n\u001b[0;32m     45\u001b[0m resized_img\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mresize(crop_img,(\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m100\u001b[39m)) \u001b[38;5;66;03m# Increase image size for better recognition\u001b[39;00m\n\u001b[0;32m     46\u001b[0m resized_img_flatten \u001b[38;5;241m=\u001b[39m resized_img\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 47\u001b[0m output\u001b[38;5;241m=\u001b[39m\u001b[43mknn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresized_img_flatten\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m ts\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     49\u001b[0m timestamp\u001b[38;5;241m=\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mfromtimestamp(ts)\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\face\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:271\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(probabilities, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[1;32m--> 271\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\face\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:826\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    824\u001b[0m         X \u001b[38;5;241m=\u001b[39m _check_precomputed(X)\n\u001b[0;32m    825\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 826\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    828\u001b[0m n_samples_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples_fit_\n\u001b[0;32m    829\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_neighbors \u001b[38;5;241m>\u001b[39m n_samples_fit:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\face\\Lib\\site-packages\\sklearn\\base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\face\\Lib\\site-packages\\sklearn\\base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    446\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 30000 features, but KNeighborsClassifier is expecting 3750 features as input."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os \n",
    "import csv\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from datetime import datetime\n",
    "\n",
    "from win32com.client import Dispatch\n",
    "\n",
    "def speak(str1):\n",
    "    speak=Dispatch((\"SAPI.SpVoice\"))\n",
    "    speak.Speak(str1)\n",
    "\n",
    "video=cv2.VideoCapture(0)\n",
    "\n",
    "facedetect=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "with open('data/names.pkl','rb') as w:\n",
    "    LABELS=pickle.load(w)\n",
    "\n",
    "with open('data/face_data.pkl','rb') as f:\n",
    "    FACES=pickle.load(f)\n",
    "\n",
    "knn=KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(FACES,LABELS)\n",
    "\n",
    "imgbackground=cv2.imread(\"bg.png\")#picture to be inputted\n",
    "\n",
    "COL_NAMES=['NAME','TIME']\n",
    "\n",
    "ts = time.time()\n",
    "date = datetime.fromtimestamp(ts).strftime(\"%d-%m-%Y\")\n",
    "attendance_file_path = \"attendance/attendance_\"+date+\".csv\"\n",
    "\n",
    "while True:\n",
    "    ret,frame=video.read()\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    face=facedetect.detectMultiScale(gray,1.3,5)\n",
    "\n",
    "    for (x,y,w,h) in face:\n",
    "        crop_img=frame[y:y+h,x:x+w,:]\n",
    "        resized_img=cv2.resize(crop_img,(100,100)) # Increase image size for better recognition\n",
    "        resized_img_flatten = resized_img.flatten().reshape(1,-1)\n",
    "        output=knn.predict(resized_img_flatten)\n",
    "        ts=time.time()\n",
    "        timestamp=datetime.fromtimestamp(ts).strftime(\"%H:%M-%S\")\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255),1)\n",
    "        cv2.putText(frame, output[0], (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
    "        attendance=[output[0], timestamp]\n",
    "\n",
    "        imgbackground[162:162+480,55:55+640]=frame\n",
    "        cv2.imshow(\"frame\",imgbackground)\n",
    "\n",
    "    k=cv2.waitKey(1)\n",
    "    if k==ord('o'):\n",
    "        speak(\"Attendance Taken..\")\n",
    "        time.sleep(5)\n",
    "\n",
    "        with open(attendance_file_path, \"a\", newline=\"\") as csvfile:\n",
    "            writer=csv.writer(csvfile)\n",
    "            if not os.path.isfile(attendance_file_path):\n",
    "                writer.writerow(COL_NAMES)\n",
    "            writer.writerow(attendance)\n",
    "\n",
    "    if k==ord('q'):\n",
    "        break\n",
    "\n",
    "video.release() \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95c1758",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face",
   "language": "python",
   "name": "face"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
